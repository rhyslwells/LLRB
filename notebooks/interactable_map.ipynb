{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df01871",
   "metadata": {},
   "source": [
    "Get clean data.\n",
    "\n",
    "Make sliders for time periods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6b8b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Name                                           Location  \\\n",
      "0     Perle Legacy Homes  Langley, Abbotsford, Delta, Maple Ridge, Surre...   \n",
      "1     Mr Build Vancouver                                        Shaughnessy   \n",
      "2  Tessella Construction                                           Squamish   \n",
      "3         Paragon Valley  Aldergrove, Fraser Valley, Surrey, White Rock,...   \n",
      "4            Vansa Renos              Coquitlam, Vancouver, North Vancouver   \n",
      "\n",
      "                         Cost  \n",
      "0                         NaN  \n",
      "1                $13K (+gst)   \n",
      "2                         NaN  \n",
      "3  CAD 10,000 - CAD 1,000,000  \n",
      "4       CAD 5,000 - 6 million  \n",
      "    min_cost   max_cost\n",
      "1       13.0       13.0\n",
      "3    10000.0  1000000.0\n",
      "4     5000.0        6.0\n",
      "5    20000.0  5000000.0\n",
      "6    20000.0   500000.0\n",
      "..       ...        ...\n",
      "110  50000.0    50000.0\n",
      "111  25000.0  1000000.0\n",
      "113    500.0   150000.0\n",
      "114  15000.0   600000.0\n",
      "115   5000.0  1000000.0\n",
      "\n",
      "[88 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cz/570p77r57bl87g4_l6l7xqw00000gn/T/ipykernel_22330/3235195242.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "data = pd.read_csv('companies.csv')\n",
    "print(data.head())\n",
    "\n",
    "def clean_and_convert(value):\n",
    "    if pd.isna(value) or \"N/A\" in value.upper():\n",
    "        return [pd.NA, pd.NA]\n",
    "\n",
    "    # Remove unwanted characters but keep the hyphen if it's surrounded by spaces (which indicates a range)\n",
    "    value = re.sub(r'[^0-9.-]+', '', value.replace(' - ', '-').upper())\n",
    "    \n",
    "    # Split the value by hyphen if it's a range, otherwise put it in a single-element list\n",
    "    numbers = value.split('-') if '-' in value else [value]\n",
    "\n",
    "    # Remove any remaining non-numeric characters and convert to float\n",
    "    min_val = float(re.sub(r'[^0-9.]+', '', numbers[0])) if numbers[0] else pd.NA\n",
    "    max_val = float(re.sub(r'[^0-9.]+', '', numbers[1])) if len(numbers) > 1 and numbers[1] else min_val\n",
    "    \n",
    "    return [min_val, max_val]\n",
    "\n",
    "\n",
    "data['cleaned_cost'] = data['Cost'].apply(clean_and_convert)\n",
    "\n",
    "# Split the 'cleaned_cost' into two separate columns\n",
    "data[['min_cost', 'max_cost']] = pd.DataFrame(data['cleaned_cost'].tolist(), index=data.index)\n",
    "\n",
    "# Drop the temporary 'cleaned_cost' column\n",
    "data.drop('cleaned_cost', axis=1, inplace=True)\n",
    "data.dropna(subset=['min_cost', 'max_cost'], how='all', inplace=True)\n",
    "\n",
    "# Display the result\n",
    "print(data[['min_cost', 'max_cost']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775b3a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Company       Location  min_cost   max_cost\n",
      "0  Mr Build Vancouver    Shaughnessy      13.0       13.0\n",
      "1      Paragon Valley     Aldergrove   10000.0  1000000.0\n",
      "2      Paragon Valley  Fraser Valley   10000.0  1000000.0\n",
      "3      Paragon Valley         Surrey   10000.0  1000000.0\n",
      "4      Paragon Valley     White Rock   10000.0  1000000.0\n"
     ]
    }
   ],
   "source": [
    "expanded_rows = []\n",
    "\n",
    "# Iterate over each row in the original DataFrame\n",
    "for index, row in data.iterrows():\n",
    "    # Split the 'Location' column based on commas\n",
    "    locations = row['Location'].split(', ')\n",
    "    # For each location, create a new row with the company, the individual location, and the cost range\n",
    "    for location in locations:\n",
    "        expanded_rows.append({\n",
    "            'Company': row['Name'],\n",
    "            'Location': location.strip(),  # Strip any leading/trailing whitespace\n",
    "            'min_cost': row['min_cost'],\n",
    "            'max_cost': row['max_cost']\n",
    "        })\n",
    "        \n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "print(expanded_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab0c784",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "initializing a Series from a MultiIndex is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mNA, pd\u001b[38;5;241m.\u001b[39mNA\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Apply geocoding to each location in the DataFrame\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m expanded_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mexpanded_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLocation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeocode_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m expanded_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(expanded_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist(), index\u001b[38;5;241m=\u001b[39mexpanded_df\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:4904\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:1516\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   1517\u001b[0m         obj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1518\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/series.py:502\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    499\u001b[0m         data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, MultiIndex):\n\u001b[0;32m--> 502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitializing a Series from a MultiIndex is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[1;32m    506\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Index):\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: initializing a Series from a MultiIndex is not supported"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Function to geocode a location\n",
    "def geocode_location(location):\n",
    "    try:\n",
    "        # Attempt to geocode the location\n",
    "        geocoded_location = geocode(f\"{location}, BC, Canada\",timeout = 5)\n",
    "        return geocoded_location.latitude, geocoded_location.longitude\n",
    "    except:\n",
    "        # Return NA values if geocoding fails\n",
    "        return pd.NA, pd.NA\n",
    "\n",
    "# Apply geocoding to each location in the DataFrame\n",
    "expanded_df['coords'] = expanded_df['Location'].apply(geocode_location)\n",
    "expanded_df[['latitude', 'longitude']] = pd.DataFrame(expanded_df['coords'].tolist(), index=expanded_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275bbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by location and compute the mean of the min and max costs\n",
    "aggregated_df = expanded_df.groupby('Location').agg({\n",
    "    'min_cost': 'mean',\n",
    "    'max_cost': 'mean',\n",
    "    'latitude': 'first',  # Since all latitudes for the same location should be equal\n",
    "    'longitude': 'first'  # Ditto for longitudes\n",
    "}).reset_index()\n",
    "\n",
    "expanded_df = expanded_df[expanded_df['Location'] != 'Su']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2623fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize cost data to range from 0 to 1 for heat map intensity\n",
    "max_cost = aggregated_df['max_cost'].max()\n",
    "aggregated_df['cost_weight'] = aggregated_df['max_cost'] / max_cost\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Create a map centered around BC, Canada\n",
    "map_center = aggregated_df[['latitude', 'longitude']].dropna().mean().tolist()\n",
    "map = folium.Map(location=map_center, zoom_start=6)\n",
    "\n",
    "# List of points for the heat map: lat, lng, and the weight\n",
    "heat_data = [\n",
    "    (row['latitude'], row['longitude'], row['cost_weight']) \n",
    "    for index, row in aggregated_df.iterrows()\n",
    "    if pd.notna(row['latitude']) and pd.notna(row['longitude'])\n",
    "]\n",
    "\n",
    "# Add the heat map layer\n",
    "HeatMap(heat_data).add_to(map)\n",
    "\n",
    "# Save to an HTML file\n",
    "map.save('heat_map.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'expanded_df' is already loaded and includes latitude and longitude\n",
    "# Calculate the average cost\n",
    "expanded_df['average_cost'] = (expanded_df['min_cost'] + expanded_df['max_cost']) / 2\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=expanded_df['longitude'],\n",
    "    y=expanded_df['latitude'],\n",
    "    z=expanded_df['average_cost'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        color=expanded_df['average_cost'],    # Set color according to average cost\n",
    "        colorscale='Viridis',                 # Color scale for visualization\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    text=expanded_df['Company']              # Hover text\n",
    ")])\n",
    "\n",
    "# Update plot layout\n",
    "fig.update_layout(\n",
    "    title='3D Plot of Companies by Location and Average Cost',\n",
    "    scene=dict(\n",
    "        xaxis_title='Longitude',\n",
    "        yaxis_title='Latitude',\n",
    "        zaxis_title='Average Cost'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=0)          # Tight layout\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Optionally, save the plot to an HTML file\n",
    "fig.write_html('3D_scatter_plot.html')\n",
    "\n",
    "expanded_df.to_csv('processed_companies.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b5553d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Company'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Company'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      2\u001b[0m aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43maggregated_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompany\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Normalize the cost data\u001b[39;00m\n\u001b[1;32m      6\u001b[0m aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_cost_normalized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_cost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m aggregated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_cost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin())\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Company'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "expanded_df['Location'] = expanded_df['Location'].astype('category')\n",
    "expanded_df['Company'] = expanded_df['Company'].astype('category')\n",
    "\n",
    "# Normalize the cost data\n",
    "expanded_df['min_cost_normalized'] = (expanded_df['min_cost'] - expanded_df['min_cost'].min()) / (expanded_df['min_cost'].max() - expanded_df['min_cost'].min())\n",
    "expanded_df['max_cost_normalized'] = (expanded_df['max_cost'] - expanded_df['max_cost'].min()) / (expanded_df['max_cost'].max() - expanded_df['max_cost'].min())\n",
    "\n",
    "fig = px.parallel_coordinates(expanded_df, \n",
    "                              dimensions=['Company', 'Location', 'min_cost_normalized', 'max_cost_normalized'],\n",
    "                              labels={'min_cost_normalized': 'Minimum Cost',\n",
    "                                      'max_cost_normalized': 'Maximum Cost',\n",
    "                                      'Location': 'Location',\n",
    "                                      'Company': 'Company Name'},\n",
    "                              color='min_cost_normalized',\n",
    "                              color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                              title='Parallel Coordinates: Company Costs by Location')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f650f947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
