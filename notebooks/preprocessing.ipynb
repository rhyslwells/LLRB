{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a554e2",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a355cb",
   "metadata": {},
   "source": [
    "We now clean more involved features. Due to the data set being relatively small we are able to manually preprerocess given features. We start with 'data/preprocessed_dates_time_data.csv' and work to obtain \"data\\cleaned.csv\". In particular we preprocess:\n",
    "\n",
    "- location\n",
    "- details and tags\n",
    "- crew\n",
    "- pager code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508e52a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd17187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "099696c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"..\\data\\cleaned.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to get rows where 'pager_code' \n",
    "value=\"333\"\n",
    "filtered_df = df[df['pager_code'] == value]\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "filtered_df[['pager_code', 'shout_details']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de1ca6",
   "metadata": {},
   "source": [
    "# Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f688b",
   "metadata": {},
   "source": [
    "Based on misspellings of locations and vague descriptions (e.g., \"south of Ardlui\") we have to make some assumptions to give better location data. If the location is for say \"south of Ardlui\" we record the location \"Ardlui\"  and in adjustment_km we record (s,2) to mean south by 2km - we take 2km as a rough estimate of the distance south.\n",
    "\n",
    "We manually input the longitude and latitude coordinates with google maps (DD format). We input the coordinates of the location (Ardlui) using Google Maps and record the core latitude longitude (core_long_lat). It's important to note that the specific location may not be precise during search operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e0c68",
   "metadata": {},
   "source": [
    "## Automation of position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee6d6f",
   "metadata": {},
   "source": [
    "To-do:\n",
    "\n",
    "    -[ ] Utilize geopy to obtain the coordinates of the location based on the shout's location (so we can automate the process).\n",
    "    -[ ] Implement functionality to accept What3Words coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d866d34d",
   "metadata": {},
   "source": [
    "Provide a function that takes a location and provides core_long_lat value.\n",
    "\n",
    "Given a map and location data need to be able to convert to longitude/latitude data.\n",
    "\n",
    "https://geopy.readthedocs.io/en/stable/index.html?highlight=what%20three%20words#geopy.geocoders.What3WordsV3.geocode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f93e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b93e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_loc=[\n",
    " 'Ardlui',\n",
    " 'Duckbay']\n",
    "\n",
    "# for df take only rows with location values in simple_loc\n",
    "filtered_df = df[df['location_of_shout'].str.contains('|'.join(simple_loc), case=False, na=False)]\n",
    "filtered_df.head()\n",
    "df=filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfe06b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"my_geocoder\")\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# Function to geocode a location\n",
    "def geocode_location(location):\n",
    "    try:\n",
    "        # Attempt to geocode the location\n",
    "        geocoded_location = geocode(f\"{location}, Scotland\",timeout = 5)\n",
    "        return geocoded_location.latitude, geocoded_location.longitude\n",
    "    except:\n",
    "        # Return NA values if geocoding fails\n",
    "        return pd.NA, pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3402cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RhysL\\AppData\\Local\\Temp\\ipykernel_23632\\3698374974.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['coords'] = df['location_of_shout'].apply(geocode_location)\n",
      "C:\\Users\\RhysL\\AppData\\Local\\Temp\\ipykernel_23632\\3698374974.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['latitude', 'longitude']] = pd.DataFrame(df['coords'].tolist(), index=df.index)\n",
      "C:\\Users\\RhysL\\AppData\\Local\\Temp\\ipykernel_23632\\3698374974.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['latitude', 'longitude']] = pd.DataFrame(df['coords'].tolist(), index=df.index)\n"
     ]
    }
   ],
   "source": [
    "# Apply geocoding to each location in the DataFrame\n",
    "df['coords'] = df['location_of_shout'].apply(geocode_location)\n",
    "df[['latitude', 'longitude']] = pd.DataFrame(df['coords'].tolist(), index=df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a88faca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_of_shout</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ardlui marina.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ardlui</td>\n",
       "      <td>56.301844</td>\n",
       "      <td>-4.721605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ardlui marina</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Between Inchmurrin and Duckbay marina</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Duckbay</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       location_of_shout   latitude longitude\n",
       "0                         Ardlui marina.       None      None\n",
       "1                                 Ardlui  56.301844 -4.721605\n",
       "2                          Ardlui marina       None      None\n",
       "3  Between Inchmurrin and Duckbay marina       None      None\n",
       "4                                Duckbay       None      None"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Group by location and determine number of call outs per year.\n",
    "aggregated_df = df.groupby('location_of_shout').agg({\n",
    "    'latitude': 'first',  # Since all latitudes for the same location should be equal\n",
    "    'longitude': 'first'  # Ditto for longitudes\n",
    "}).reset_index()\n",
    "\n",
    "aggregated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705beb0e",
   "metadata": {},
   "source": [
    "# Details and tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c24907d",
   "metadata": {},
   "source": [
    "For each shout_detail item we provide shout_details_tags as a way to quickly understand the incident. Here are the tags and details they correspond to:\n",
    "\n",
    "Tag categories:\n",
    "- Mechanical\n",
    "- Rescue\n",
    "- Medical\n",
    "- Environmental\n",
    "- Mishap\n",
    "- Assistance\n",
    "- FalseAlarm\n",
    "- Miscellaneous\n",
    "- Search\n",
    "- Transport\n",
    "\n",
    "See docs/tag_categories.md for what into each category. To obtain shout_detail_tags we read each shout_detail and manually input the tags. Alternatively one could use a LLM to classify based on tags, see docs/detail_tag_prompt.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76274f94",
   "metadata": {},
   "source": [
    "Reading through the shout-detials we see that LLRB also work with the follwoing organisations:\n",
    "- SAS\n",
    "- LLTNP\n",
    "- DMMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9440bc3",
   "metadata": {},
   "source": [
    "# Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a55a1f",
   "metadata": {},
   "source": [
    "We parsed weather_at_time_of_shout manually into a comma separated list of weather conditions. \n",
    "\n",
    "We record these changes in:\n",
    "\n",
    "\"data\\codes_preprocessed_dates_time_data.csv\"\n",
    "\n",
    "Sometimes they record what the waves (the chop/swell level),temperature, light level,wind direction and strength, and visability level.\n",
    "\n",
    "We can ask the crew to record these details at the time of the incident."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072be6a",
   "metadata": {},
   "source": [
    "# pager_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462b17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e0d7b11",
   "metadata": {},
   "source": [
    "Pager codes initially are formed of three leading terms these are:\n",
    "\n",
    "- 999 = someone in water,\n",
    "- 333 = search, \n",
    "- 222 = urgent but no threat to life\n",
    "\n",
    "Sometimes the main-pager-codes are followed by a sub-pager-code. We do not know what these sub-pager-codes refer to (we leave these for now).\n",
    "\n",
    "LLRB often gets called out without need for a pager code, or with AIRWAVE. This occurs while out on training or on a previous callout.\n",
    "\n",
    "\n",
    "We will ask the crew to provide more information on these. If they are not able to provide more information we will will leave the pager-codes as they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784d532",
   "metadata": {},
   "source": [
    "Given pager_code take first three letters as the code, if there are more than three letters, take the next three letters as subcode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38b548ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pager_code'].fillna(\"Na\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e65a4b9",
   "metadata": {},
   "source": [
    "Identify all rows that begin with 999,333,222 and have a subcode. Extract subcode and put into subcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d595be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First put all subcodes as None\n",
    "df['subcode']=None\n",
    "\n",
    "#First: Identify all rows that are of form 999,333,222 only. \n",
    "\n",
    "# Identify all rows that are of form 999,333,222 only. For the subcode put None.\n",
    "df_pager_main_only = df['pager_code'].apply(lambda x: x if x in ['999','333','222'] else None)\n",
    "# df_pager_main_only.value_counts()\n",
    "\n",
    "#Now get subcodes for the rest of the rows\n",
    "\n",
    "df['subcode'] = df['pager_code'].apply(lambda x: str(x)[3:] if x not in df_pager_main_only else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc8601",
   "metadata": {},
   "source": [
    "Extract rows that do not start with a pager code of the form 999,333,222."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65326728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pager_code\n",
       "Na                                     50\n",
       "other / already out                     5\n",
       "On water                                2\n",
       "AIRWAVE                                 2\n",
       "Na on water                             2\n",
       "Nil                                     1\n",
       "N/A   AB messaged                       1\n",
       "N/a                                     1\n",
       "3032                                    1\n",
       "Na already on water at safety event     1\n",
       "11:30                                   1\n",
       "Na already out                          1\n",
       "Na just returned from previous          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identify all rows that do not start with:  999,333,222.\n",
    "\n",
    "df_non = df[~df['pager_code'].astype(str).str.match(r'^(999|333|222)')]\n",
    "# print(df_non.shape) #69\n",
    "df_non['pager_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ea441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save those that begin with 999,333,222\n",
    "df_main = df[df['pager_code'].astype(str).str.match(r'^(999|333|222)')]\n",
    "\n",
    "# Once pager_code has be entered for those without (df_non), concate df_main and created df_non_entered.\n",
    "# identify those pager_codes that need to be entered in for based on shout_details.\n",
    "#See pager code descriptions\n",
    "\n",
    "# save df_non to csv\n",
    "# df_non.to_csv('../data/pager_codes_missing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b77423",
   "metadata": {},
   "source": [
    "# 'crew_on_board' and 'crew_on_shore'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1024ef75",
   "metadata": {},
   "source": [
    "Ask those recording to record the initials of the crew on board and on shore in a comma separated list. If there are no crew on board or on shore, record as \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bba1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"RB\": \"Ronnie Britton\",\n",
    "    \"RO\": \"Rennie Oliver\",\n",
    "    \"IG\": \"Iain Gollan (Goz)\",\n",
    "    \"AM\": \"Ally McLeod\",\n",
    "    \"ABS\": \"Andy Biddulph Snr\",\n",
    "    \"ABJ\": \"Andy Biddulph Jnr\",\n",
    "    \"GD\": \"Gemma Dorran\",\n",
    "    \"PBT\": \"Phils Brooks-Taylor\",\n",
    "    \"DON\": \"David O'Neil\",\n",
    "    \"CC\": \"Craig Clancy\",\n",
    "    \"GH\": \"Gerry Heaney\",\n",
    "    \"AJM\": \"Angus John MacDonald\",\n",
    "    \"CMS\": \"Callum MacKenzie Stevens\",\n",
    "    \"DS\": \"David Stuart\",\n",
    "    \"TR\": \"Thomas Rogers\",\n",
    "    \"EM\": \"Euan MciIwraith\",\n",
    "    \"PD\": \"Paul Dorrian\",\n",
    "    \"KM\": \"Kevin McPartland\",\n",
    "    \"JB\": \"Jenna Biddulph\",\n",
    "    \"VM\": \"Vicki Murphy\",\n",
    "    \"JM\": \"John Mason\",\n",
    "    \"AC\": \"Andy Connell\",\n",
    "    \"FN\": \"Franny Nicol\",\n",
    "    \"FR\": \"Frank Rogers\",\n",
    "    \"CA\": \"Christine Allan\",\n",
    "    \"CS\": \"Clinton Salter\"\n",
    "    \"JT\": \"James Thomson\",\n",
    "    \"TAM\":\"Tam (Cox)\",\n",
    "    \"GERARD\",\"Gerard\",\n",
    "    \"DAVY\",\"Davy\",\n",
    "    \"LEE\",\"Lee\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60734305",
   "metadata": {},
   "source": [
    "#TODO! \n",
    "\n",
    "Remember to convert weather, details and location to lower case.\n",
    "\n",
    "Ensure crew spaces are removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"..\\data\\codes_preprocessed_dates_time_data.csv\")\n",
    "# df.drop(columns=[\"shout_details\"], inplace=True)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn values into comma separated values.\n",
    "# Keep as Initials for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crew_on_board'].fillna(\"Na\", inplace=True)\n",
    "df['crew_on_shore'].fillna(\"Na\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "451ac435",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=['crew_on_board', 'crew_on_shore']\n",
    "df[feats].head()\n",
    "df_crew=df[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b96611",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crew.value_counts()\n",
    "#For crew_on_board\n",
    "# seperate comma serparated values for each row. \n",
    "#count the number of times a given name appears.\n",
    "\n",
    "#For a given name get a list of pager_codes that they have been on board for.\n",
    "# Similarly get the weather for this persons callouts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
